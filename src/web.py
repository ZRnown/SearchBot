from __future__ import annotations

import os
import zipfile
import tempfile
import shutil
import asyncio
from datetime import datetime, timedelta, timezone
from typing import Annotated, List, Optional
from pathlib import Path

import logging

try:
    import rarfile
    RAR_SUPPORT = True
except ImportError:
    RAR_SUPPORT = False

from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.types import BufferedInputFile, InlineKeyboardButton, InlineKeyboardMarkup, InputMediaPhoto
from aiogram.exceptions import TelegramRetryAfter, TelegramAPIError
from fastapi import Body, Depends, FastAPI, File, Form, HTTPException, Query, Response, UploadFile, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer
from pydantic import BaseModel, Field
from jose import JWTError, jwt
from passlib.context import CryptContext

from sqlalchemy import String

from .config import settings
from .db import AdminUser, ComicFile, PaymentConfig, Resource, SearchButton, User, VipPlan, db_session, init_db


class ResourceResponse(BaseModel):
    id: str
    title: str
    type: str
    is_vip: bool
    link: str
    preview_link: Optional[str] = None
    deep_link: Optional[str] = None
    created_at: datetime


class ComicUploadResponse(BaseModel):
    id: str
    pages: int
    deep_link: str
    preview_link: Optional[str] = None


class ComicFileResponse(BaseModel):
    id: int
    file_id: str
    order: int


class ComicFilesResponse(BaseModel):
    resource_id: str
    title: str
    files: List[ComicFileResponse]


class UpdateComicFilesOrderRequest(BaseModel):
    file_orders: List[dict] = Field(..., description="List of {id: int, order: int}")


class SettingsResponse(BaseModel):
    page_size: int
    search_channel_id: int
    comic_preview_channel_id: int
    storage_channel_id: int


class LoginRequest(BaseModel):
    username: str
    password: str


class TokenResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"
    expires_in: int


class ChangePasswordRequest(BaseModel):
    current_password: str
    new_password: str


class ProfileResponse(BaseModel):
    username: str


class UserResponse(BaseModel):
    user_id: int
    first_name: Optional[str]
    username: Optional[str]
    vip_expiry: Optional[datetime]
    is_blocked: bool
    usage_quota: int
    created_at: datetime
    updated_at: datetime


class UserCreateIn(BaseModel):
    user_id: int
    first_name: Optional[str] = None
    username: Optional[str] = None
    vip_expiry: Optional[datetime] = None
    is_blocked: bool = False


class UserUpdateIn(BaseModel):
    first_name: Optional[str] = None
    username: Optional[str] = None
    vip_expiry: Optional[datetime] = None
    is_blocked: Optional[bool] = None


class VipPlanResponse(BaseModel):
    id: int
    name: str
    duration_days: int
    price: str
    description: Optional[str]
    is_active: bool
    sort_order: int
    created_at: datetime
    updated_at: datetime


class VipPlanCreateIn(BaseModel):
    name: str
    duration_days: int
    price: str
    description: Optional[str] = None
    is_active: bool = True
    sort_order: int = 0


class VipPlanUpdateIn(BaseModel):
    name: Optional[str] = None
    duration_days: Optional[int] = None
    price: Optional[str] = None
    description: Optional[str] = None
    is_active: Optional[bool] = None
    sort_order: Optional[int] = None


class PaymentConfigResponse(BaseModel):
    id: int
    payment_type: str
    account_name: Optional[str]
    account_number: Optional[str]
    qr_code_url: Optional[str]
    qr_code_file_id: Optional[str]
    is_active: bool
    sort_order: int
    created_at: datetime
    updated_at: datetime


class PaymentConfigCreateIn(BaseModel):
    payment_type: str
    account_name: Optional[str] = None
    account_number: Optional[str] = None
    qr_code_url: Optional[str] = None
    qr_code_file_id: Optional[str] = None
    is_active: bool = True
    sort_order: int = 0


class PaymentConfigUpdateIn(BaseModel):
    account_name: Optional[str] = None
    account_number: Optional[str] = None
    qr_code_url: Optional[str] = None
    qr_code_file_id: Optional[str] = None
    is_active: Optional[bool] = None
    sort_order: Optional[int] = None


class VipPaymentInfoResponse(BaseModel):
    plans: List[VipPlanResponse]
    wechat_config: Optional[PaymentConfigResponse] = None
    alipay_config: Optional[PaymentConfigResponse] = None


logger = logging.getLogger(__name__)
MAX_BCRYPT_BYTES = 72
# é…ç½® FastAPI ä»¥æ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ 
app = FastAPI(
    title="Resource Admin Panel",
    # æ³¨æ„ï¼šæ–‡ä»¶å¤§å°é™åˆ¶åœ¨ uvicorn å¯åŠ¨å‚æ•°ä¸­é…ç½®
)
admin_bot = Bot(
    token=settings.bot_token,
    default=DefaultBotProperties(parse_mode="HTML"),
)
_bot_username: Optional[str] = None
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/login")
ALGORITHM = "HS256"

allowed_origins = os.getenv("ADMIN_PANEL_ORIGINS", "*")
origins = (
    ["*"]
    if allowed_origins.strip() == "*"
    else [origin.strip() for origin in allowed_origins.split(",") if origin.strip()]
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def _normalize_password(password: str) -> str:
    encoded = password.encode("utf-8")
    if len(encoded) > MAX_BCRYPT_BYTES:
        logger.warning(
            "Admin password exceeds bcrypt 72-byte limit; extra bytes will be truncated."
        )
    return encoded[:MAX_BCRYPT_BYTES].decode("utf-8", "ignore")


def hash_password(password: str) -> str:
    return pwd_context.hash(_normalize_password(password))


def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(_normalize_password(plain_password), hashed_password)


def ensure_default_admin() -> None:
    with db_session() as session:
        admin = session.query(AdminUser).filter(AdminUser.username == settings.web_admin_user).first()
        if not admin:
            session.add(
                AdminUser(
                    username=settings.web_admin_user,
                    password_hash=hash_password(settings.web_admin_pass),
                )
            )


async def ensure_comic_preview_links() -> None:
    with db_session() as session:
        missing = (
            session.query(Resource)
            .filter(Resource.type == "comic")
            .filter((Resource.preview_url == None) | (Resource.preview_url == ""))
            .all()
        )
        if not missing:
            return
        bot_username = await get_bot_username()
        for resource in missing:
            resource.preview_url = f"https://t.me/{bot_username}?start=comic_{resource.id}"
        session.flush()


def create_access_token(*, subject: str, expires_delta: Optional[timedelta] = None) -> str:
    to_encode = {"sub": subject}
    expire = datetime.now(timezone.utc) + (
        expires_delta or timedelta(minutes=settings.security.token_expire_minutes)
    )
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, settings.security.jwt_secret, algorithm=ALGORITHM)


def require_admin(token: str = Depends(oauth2_scheme)) -> str:
    credentials_exception = HTTPException(
        status_code=401,
        detail="æ— æ•ˆçš„è®¤è¯ä¿¡æ¯",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.security.jwt_secret, algorithms=[ALGORITHM])
        username: str | None = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    return username


class IndexedResourceIn(BaseModel):
    title: str = Field(..., max_length=255)
    type: str = Field(..., pattern="^(novel|audio)$")
    jump_url: str


class ResourceUpdateIn(BaseModel):
    title: Optional[str] = Field(None, max_length=255)
    jump_url: Optional[str] = None
    preview_url: Optional[str] = None


class IndexedResourceOut(BaseModel):
    id: str
    title: str
    type: str
    link: str


class SearchButtonIn(BaseModel):
    label: str = Field(..., max_length=64)
    url: str = Field(..., max_length=255)
    sort_order: int = Field(0, ge=0)


class SearchButtonResponse(BaseModel):
    id: int
    label: str
    url: str
    sort_order: int


async def get_bot_username() -> str:
    global _bot_username
    if _bot_username is None:
        me = await admin_bot.get_me()
        _bot_username = me.username or "MainBot"
    return _bot_username


@app.on_event("startup")
async def _startup() -> None:
    init_db()
    ensure_default_admin()
    await ensure_comic_preview_links()


@app.on_event("shutdown")
async def _shutdown() -> None:
    await admin_bot.session.close()


@app.get("/healthz")
async def healthz():
    return {"status": "ok"}


async def send_photo_with_retry(
    bot: Bot,
    chat_id: int,
    photo: BufferedInputFile | str,
    max_retries: int = 3,
    initial_delay: float = 1.0,
) -> any:
    """å‘é€å›¾ç‰‡ï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œ Flood control å¤„ç†"""
    for attempt in range(max_retries):
        try:
            message = await bot.send_photo(chat_id, photo=photo)
            return message
        except TelegramRetryAfter as e:
            wait_time = e.retry_after + 1  # å¤šç­‰1ç§’
            logger.warning(f"è§¦å‘ Flood controlï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
            await asyncio.sleep(wait_time)
        except TelegramAPIError as e:
            if attempt < max_retries - 1:
                wait_time = initial_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logger.warning(f"å‘é€å›¾ç‰‡å¤±è´¥ï¼Œ{wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}): {e}")
                await asyncio.sleep(wait_time)
            else:
                raise
    raise Exception(f"å‘é€å›¾ç‰‡å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")


async def delete_message_with_retry(
    bot: Bot,
    chat_id: int,
    message_id: int,
    max_retries: int = 3,
    initial_delay: float = 1.0,
) -> bool:
    """åˆ é™¤æ¶ˆæ¯ï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œ Flood control å¤„ç†
    
    Returns:
        bool: True å¦‚æœåˆ é™¤æˆåŠŸï¼ŒFalse å¦‚æœæ¶ˆæ¯ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤
    """
    for attempt in range(max_retries):
        try:
            await bot.delete_message(chat_id=chat_id, message_id=message_id)
            return True
        except TelegramRetryAfter as e:
            wait_time = e.retry_after + 1  # å¤šç­‰1ç§’
            logger.warning(f"åˆ é™¤æ¶ˆæ¯è§¦å‘ Flood controlï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}, message_id={message_id})")
            await asyncio.sleep(wait_time)
        except TelegramAPIError as e:
            error_message = str(e).lower()
            # æ¶ˆæ¯ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            if "message to delete not found" in error_message or "message can't be deleted" in error_message:
                logger.info(f"æ¶ˆæ¯ {message_id} ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
                return False
            # å…¶ä»–é”™è¯¯ï¼Œå¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•åˆ™è¿”å› Falseï¼Œå¦åˆ™é‡è¯•
            if attempt < max_retries - 1:
                wait_time = initial_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logger.warning(f"åˆ é™¤æ¶ˆæ¯å¤±è´¥ï¼Œ{wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}, message_id={message_id}): {e}")
                await asyncio.sleep(wait_time)
            else:
                logger.error(f"åˆ é™¤æ¶ˆæ¯å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡ (message_id={message_id}): {e}")
                return False
    return False


def format_channel_id_for_link(channel_id: int) -> str:
    """å°† Telegram é¢‘é“ ID æ ¼å¼åŒ–ä¸ºé“¾æ¥æ ¼å¼ï¼ˆå»æ‰ -100 å‰ç¼€ï¼‰"""
    channel_str = str(abs(channel_id))
    if channel_str.startswith("100"):
        return channel_str[3:]  # å»æ‰ "100" å‰ç¼€
    return channel_str


def build_resource_link(resource: Resource, bot_username: Optional[str] = None) -> str:
    if resource.type in {"novel", "audio"}:
        return resource.jump_url or ""
    if resource.preview_url:
        return resource.preview_url
    if bot_username:
        return f"https://t.me/{bot_username}?start=comic_{resource.id}"
    if resource.preview_message_id:
        formatted_id = format_channel_id_for_link(settings.channels.comic_preview_channel_id)
        return f"https://t.me/c/{formatted_id}/{resource.preview_message_id}"
    return ""


def build_resource_response(resource: Resource, bot_username: Optional[str]) -> ResourceResponse:
    deep_link = (
        f"https://t.me/{bot_username}?start=comic_{resource.id}"
        if resource.type == "comic" and bot_username
        else None
    )
    preview_link = (
        resource.preview_url
        if resource.type == "comic"
        else resource.jump_url
    )
    if resource.type == "comic" and not preview_link and bot_username:
        preview_link = deep_link
    return ResourceResponse(
        id=resource.id,
        title=resource.title,
        type=resource.type,
        is_vip=resource.is_vip,
        link=build_resource_link(resource, bot_username),
        preview_link=preview_link,
        deep_link=deep_link,
        created_at=resource.created_at,
    )


@app.post("/auth/login", response_model=TokenResponse)
async def login(payload: LoginRequest):
    with db_session() as session:
        admin = session.query(AdminUser).filter(AdminUser.username == payload.username).first()
        if not admin or not verify_password(payload.password, admin.password_hash):
            raise HTTPException(status_code=401, detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

    token = create_access_token(subject=payload.username)
    return TokenResponse(
        access_token=token,
        expires_in=settings.security.token_expire_minutes * 60,
    )


@app.get("/auth/profile", response_model=ProfileResponse)
async def auth_profile(username: Annotated[str, Depends(require_admin)]):
    return ProfileResponse(username=username)


@app.post("/auth/change-password")
async def change_password(
    payload: ChangePasswordRequest,
    username: Annotated[str, Depends(require_admin)],
):
    if len(payload.new_password) < 8:
        raise HTTPException(status_code=400, detail="æ–°å¯†ç è‡³å°‘ 8 ä½å­—ç¬¦")
    with db_session() as session:
        admin = session.query(AdminUser).filter(AdminUser.username == username).first()
        if not admin or not verify_password(payload.current_password, admin.password_hash):
            raise HTTPException(status_code=400, detail="å½“å‰å¯†ç é”™è¯¯")
        admin.password_hash = hash_password(payload.new_password)
        session.flush()
    return {"status": "ok"}


@app.get("/resources", response_model=List[ResourceResponse])
async def list_resources(
    _: Annotated[str, Depends(require_admin)],
    resource_type: Optional[str] = Query(None, regex="^(novel|audio|comic)$"),
    skip: int = Query(0, ge=0),
    limit: int = Query(50, ge=1, le=100),
):
    bot_username = await get_bot_username()
    with db_session() as session:
        query = session.query(Resource)
        if resource_type:
            query = query.filter(Resource.type == resource_type)
        resources = query.order_by(Resource.created_at.desc()).offset(skip).limit(limit).all()
    return [build_resource_response(res, bot_username) for res in resources]


@app.get("/resources/count")
async def get_resources_count(
    _: Annotated[str, Depends(require_admin)],
    resource_type: Optional[str] = Query(None, regex="^(novel|audio|comic)$"),
):
    with db_session() as session:
        query = session.query(Resource)
        if resource_type:
            query = query.filter(Resource.type == resource_type)
        count = query.count()
    return {"count": count}


@app.delete("/resources/{resource_id}", status_code=204)
async def delete_resource(
    resource_id: str,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        resource = session.get(Resource, resource_id)
        if not resource:
            raise HTTPException(status_code=404, detail="Resource not found")
        
        # åˆ é™¤é¢„è§ˆé¢‘é“çš„æ¶ˆæ¯ï¼ˆæ”¯æŒåª’ä½“ç»„ï¼Œåˆ é™¤æ‰€æœ‰æ¶ˆæ¯ï¼‰
        preview_message_ids_to_delete = []
        if resource.preview_message_ids:
            # å¦‚æœæœ‰ preview_message_idsï¼ˆæ–°æ ¼å¼ï¼‰ï¼Œä½¿ç”¨å®ƒ
            preview_message_ids_to_delete = resource.preview_message_ids
        elif resource.preview_message_id:
            # å‘åå…¼å®¹ï¼šåªæœ‰ preview_message_idï¼ˆæ—§æ ¼å¼ï¼‰
            preview_message_ids_to_delete = [resource.preview_message_id]
        
        deleted_count = 0
        failed_count = 0
        for msg_id in preview_message_ids_to_delete:
            deleted = await delete_message_with_retry(
                bot=admin_bot,
                chat_id=settings.channels.comic_preview_channel_id,
                message_id=msg_id,
            )
            if deleted:
                deleted_count += 1
                logger.info(f"å·²åˆ é™¤é¢„è§ˆé¢‘é“æ¶ˆæ¯: {msg_id}")
            else:
                failed_count += 1
                logger.warning(f"é¢„è§ˆé¢‘é“æ¶ˆæ¯ {msg_id} åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨")
            # æ·»åŠ å°å»¶è¿Ÿé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
            await asyncio.sleep(0.1)
        
        if preview_message_ids_to_delete:
            logger.info(f"é¢„è§ˆé¢‘é“æ¶ˆæ¯åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count}/{len(preview_message_ids_to_delete)}ï¼Œå¤±è´¥ {failed_count}")
        
        # å¯¹äºæ¼«ç”»ç±»å‹ï¼Œåˆ é™¤ä»“åº“é¢‘é“çš„æ¶ˆæ¯
        if resource.type == "comic":
            comic_files = session.query(ComicFile).filter(ComicFile.resource_id == resource_id).all()
            total_files = len(comic_files)
            files_with_message_id = sum(1 for cf in comic_files if cf.storage_message_id)
            deleted_count = 0
            failed_count = 0
            
            logger.info(f"èµ„æº {resource.id} å…±æœ‰ {total_files} ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­ {files_with_message_id} ä¸ªæœ‰æ¶ˆæ¯ID")
            
            for comic_file in comic_files:
                if comic_file.storage_message_id:
                    deleted = await delete_message_with_retry(
                        bot=admin_bot,
                        chat_id=settings.channels.storage_channel_id,
                        message_id=comic_file.storage_message_id,
                    )
                    if deleted:
                        deleted_count += 1
                        logger.info(f"å·²åˆ é™¤ä»“åº“é¢‘é“æ¶ˆæ¯: {comic_file.storage_message_id}")
                    else:
                        failed_count += 1
                        logger.warning(f"ä»“åº“é¢‘é“æ¶ˆæ¯ {comic_file.storage_message_id} åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨")
                    # æ·»åŠ å°å»¶è¿Ÿé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                    await asyncio.sleep(0.1)
                else:
                    logger.warning(f"æ–‡ä»¶ {comic_file.id} (order={comic_file.order}) æ²¡æœ‰ storage_message_idï¼Œæ— æ³•åˆ é™¤")
            
            logger.info(f"èµ„æº {resource.id} åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count}/{files_with_message_id}ï¼Œå¤±è´¥ {failed_count}ï¼Œæ— æ¶ˆæ¯ID {total_files - files_with_message_id}")
        
        session.delete(resource)
        session.flush()


@app.post("/resources/batch-delete", status_code=204, response_class=Response)
async def batch_delete_resources(
    resource_ids: Annotated[List[str], Body()],
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        resources = session.query(Resource).filter(Resource.id.in_(resource_ids)).all()
        for resource in resources:
            # åˆ é™¤é¢„è§ˆé¢‘é“çš„æ¶ˆæ¯ï¼ˆæ”¯æŒåª’ä½“ç»„ï¼Œåˆ é™¤æ‰€æœ‰æ¶ˆæ¯ï¼‰
            preview_message_ids_to_delete = []
            if resource.preview_message_ids:
                # å¦‚æœæœ‰ preview_message_idsï¼ˆæ–°æ ¼å¼ï¼‰ï¼Œä½¿ç”¨å®ƒ
                preview_message_ids_to_delete = resource.preview_message_ids
            elif resource.preview_message_id:
                # å‘åå…¼å®¹ï¼šåªæœ‰ preview_message_idï¼ˆæ—§æ ¼å¼ï¼‰
                preview_message_ids_to_delete = [resource.preview_message_id]
            
            deleted_count = 0
            failed_count = 0
            for msg_id in preview_message_ids_to_delete:
                deleted = await delete_message_with_retry(
                    bot=admin_bot,
                    chat_id=settings.channels.comic_preview_channel_id,
                    message_id=msg_id,
                )
                if deleted:
                    deleted_count += 1
                    logger.info(f"å·²åˆ é™¤é¢„è§ˆé¢‘é“æ¶ˆæ¯: {msg_id}")
                else:
                    failed_count += 1
                    logger.warning(f"é¢„è§ˆé¢‘é“æ¶ˆæ¯ {msg_id} åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨")
                # æ·»åŠ å°å»¶è¿Ÿé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                await asyncio.sleep(0.1)
            
            if preview_message_ids_to_delete:
                logger.info(f"èµ„æº {resource.id} é¢„è§ˆé¢‘é“æ¶ˆæ¯åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count}/{len(preview_message_ids_to_delete)}ï¼Œå¤±è´¥ {failed_count}")
            
            # å¯¹äºæ¼«ç”»ç±»å‹ï¼Œåˆ é™¤ä»“åº“é¢‘é“çš„æ¶ˆæ¯
            if resource.type == "comic":
                comic_files = session.query(ComicFile).filter(ComicFile.resource_id == resource.id).all()
                total_files = len(comic_files)
                files_with_message_id = sum(1 for cf in comic_files if cf.storage_message_id)
                deleted_count = 0
                failed_count = 0
                
                logger.info(f"èµ„æº {resource.id} å…±æœ‰ {total_files} ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­ {files_with_message_id} ä¸ªæœ‰æ¶ˆæ¯ID")
                
                for comic_file in comic_files:
                    if comic_file.storage_message_id:
                        deleted = await delete_message_with_retry(
                            bot=admin_bot,
                            chat_id=settings.channels.storage_channel_id,
                            message_id=comic_file.storage_message_id,
                        )
                        if deleted:
                            deleted_count += 1
                            logger.info(f"å·²åˆ é™¤ä»“åº“é¢‘é“æ¶ˆæ¯: {comic_file.storage_message_id}")
                        else:
                            failed_count += 1
                            logger.warning(f"ä»“åº“é¢‘é“æ¶ˆæ¯ {comic_file.storage_message_id} åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨")
                        # æ·»åŠ å°å»¶è¿Ÿé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                        await asyncio.sleep(0.1)
                    else:
                        logger.warning(f"æ–‡ä»¶ {comic_file.id} (order={comic_file.order}) æ²¡æœ‰ storage_message_idï¼Œæ— æ³•åˆ é™¤")
                
                logger.info(f"èµ„æº {resource.id} åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count}/{files_with_message_id}ï¼Œå¤±è´¥ {failed_count}ï¼Œæ— æ¶ˆæ¯ID {total_files - files_with_message_id}")
            
            # åˆ é™¤èµ„æºï¼ˆCASCADE ä¼šè‡ªåŠ¨åˆ é™¤å…³è”çš„ comic_filesï¼‰
            session.delete(resource)
        try:
            session.flush()
        except Exception as e:
            logger.error(f"åˆ é™¤èµ„æºæ—¶å‡ºé”™: {e}")
            session.rollback()
            raise HTTPException(status_code=500, detail=f"åˆ é™¤èµ„æºå¤±è´¥: {str(e)}")
    return Response(status_code=204)


@app.get("/search-buttons", response_model=List[SearchButtonResponse])
async def list_search_buttons(_: Annotated[str, Depends(require_admin)]) -> List[SearchButtonResponse]:
    with db_session() as session:
        buttons = (
            session.query(SearchButton)
            .order_by(SearchButton.sort_order.asc(), SearchButton.id.asc())
            .all()
        )
        return [
            SearchButtonResponse(
                id=button.id,
                label=button.label,
                url=button.url,
                sort_order=button.sort_order,
            )
            for button in buttons
        ]


@app.post("/search-buttons", response_model=SearchButtonResponse)
async def create_search_button(
    payload: SearchButtonIn,
    _: Annotated[str, Depends(require_admin)],
) -> SearchButtonResponse:
    label = payload.label.strip()
    url = payload.url.strip()
    if not label or not url:
        raise HTTPException(status_code=400, detail="æŒ‰é’®æ–‡æœ¬å’Œé“¾æ¥ä¸èƒ½ä¸ºç©º")
    with db_session() as session:
        button = SearchButton(
            label=label,
            url=url,
            sort_order=payload.sort_order,
        )
        session.add(button)
        session.flush()
        return SearchButtonResponse(
            id=button.id,
            label=button.label,
            url=button.url,
            sort_order=button.sort_order,
        )


@app.put("/search-buttons/{button_id}", response_model=SearchButtonResponse)
async def update_search_button(
    button_id: int,
    payload: SearchButtonIn,
    _: Annotated[str, Depends(require_admin)],
) -> SearchButtonResponse:
    label = payload.label.strip()
    url = payload.url.strip()
    if not label or not url:
        raise HTTPException(status_code=400, detail="æŒ‰é’®æ–‡æœ¬å’Œé“¾æ¥ä¸èƒ½ä¸ºç©º")
    with db_session() as session:
        button = session.get(SearchButton, button_id)
        if not button:
            raise HTTPException(status_code=404, detail="Button not found")
        button.label = label
        button.url = url
        button.sort_order = payload.sort_order
        session.flush()
        return SearchButtonResponse(
            id=button.id,
            label=button.label,
            url=button.url,
            sort_order=button.sort_order,
        )


@app.delete("/search-buttons/{button_id}", status_code=204, response_class=Response)
async def delete_search_button(
    button_id: int,
    _: Annotated[str, Depends(require_admin)],
) -> Response:
    with db_session() as session:
        button = session.get(SearchButton, button_id)
        if not button:
            raise HTTPException(status_code=404, detail="Button not found")
        session.delete(button)
        session.flush()
    return Response(status_code=204)


@app.post("/resources/indexed", response_model=IndexedResourceOut)
async def create_indexed_resource(
    payload: IndexedResourceIn, _: Annotated[str, Depends(require_admin)]
):
    with db_session() as session:
        resource = Resource(
            title=payload.title,
            type=payload.type,
            jump_url=payload.jump_url,
            is_vip=False,
        )
        session.add(resource)
        session.flush()
        return IndexedResourceOut(
            id=resource.id,
            title=resource.title,
            type=resource.type,
            link=build_resource_link(resource),
        )


@app.put("/resources/{resource_id}", response_model=ResourceResponse)
async def update_resource(
    resource_id: str,
    payload: ResourceUpdateIn,
    _: Annotated[str, Depends(require_admin)],
):
    if (
        payload.title is None
        and payload.jump_url is None
        and payload.preview_url is None
    ):
        raise HTTPException(status_code=400, detail="æœªæä¾›æ›´æ–°å†…å®¹")
    with db_session() as session:
        resource = session.get(Resource, resource_id)
        if not resource:
            raise HTTPException(status_code=404, detail="Resource not found")
        if payload.title is not None:
            resource.title = payload.title
        if resource.type in {"novel", "audio"}:
            if payload.jump_url is not None:
                resource.jump_url = payload.jump_url
            if payload.preview_url is not None:
                resource.preview_url = payload.preview_url
            resource.is_vip = False
        elif resource.type == "comic":
            if payload.preview_url is not None:
                resource.preview_url = payload.preview_url
            if payload.jump_url is not None:
                resource.jump_url = payload.jump_url
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„èµ„æºç±»å‹")
        session.flush()
    bot_username = await get_bot_username()
    return build_resource_response(resource, bot_username)


@app.post("/resources/comics", response_model=ComicUploadResponse)
async def upload_comic(
    title: Annotated[str, Form()],
    files: Annotated[list[UploadFile], File(..., description="æŒ‰æ–‡ä»¶åæ’åºçš„å›¾ç‰‡åˆ—è¡¨")],
    _: Annotated[str, Depends(require_admin)],
    is_vip: Annotated[bool, Form()] = False,
    preview_count: Annotated[int, Form()] = 5,
):
    if not files:
        raise HTTPException(status_code=400, detail="è‡³å°‘ä¸Šä¼ ä¸€å¼ å›¾ç‰‡")

    sorted_files = sorted(files, key=lambda f: f.filename or "")
    stored_file_ids: list[str] = []
    for idx, upload in enumerate(sorted_files, start=1):
        content = await upload.read()
        buffer = BufferedInputFile(content, filename=upload.filename or f"comic_{idx}.jpg")
        message = await admin_bot.send_photo(
            settings.channels.storage_channel_id,
            photo=buffer,
        )
        if not message.photo:
            raise HTTPException(status_code=500, detail="æ— æ³•è·å–æ–‡ä»¶ ID")
        stored_file_ids.append(message.photo[-1].file_id)

    cover_file_id = stored_file_ids[0]
    bot_username = await get_bot_username()

    with db_session() as session:
        resource = Resource(
            title=title,
            type="comic",
            cover_file_id=cover_file_id,
            is_vip=is_vip,
            preview_url=None,  # è‡ªåŠ¨ç”Ÿæˆï¼Œä¸æ‰‹åŠ¨è®¾ç½®
        )
        session.add(resource)
        session.flush()

        deep_link = f"https://t.me/{bot_username}?start=comic_{resource.id}"
        
        # å‘é€å‰å‡ å¼ å›¾ç‰‡åˆ°é¢„è§ˆé¢‘é“ï¼Œç¬¬ä¸€å¼ å›¾ç‰‡çš„captionåŒ…å«è¶…é“¾æ¥
        preview_file_ids = stored_file_ids[:min(preview_count, len(stored_file_ids))]
        preview_messages = []
        for idx, file_id in enumerate(preview_file_ids):
            try:
                # ç¬¬ä¸€å¼ å›¾ç‰‡æ·»åŠ captionï¼ˆåŒ…å«è¶…é“¾æ¥ï¼‰ï¼Œå…¶ä»–å›¾ç‰‡ä¸æ·»åŠ caption
                if idx == 0:
                    caption = f'ğŸ“– <a href="{deep_link}">{title}</a>'
                    message = await admin_bot.send_photo(
                        settings.channels.comic_preview_channel_id,
                        photo=file_id,
                        caption=caption,
                        parse_mode="HTML",
                    )
                else:
                    message = await admin_bot.send_photo(
                        settings.channels.comic_preview_channel_id,
                        photo=file_id,
                    )
                preview_messages.append(message)
            except Exception as e:
                logger.error(f"å‘é€é¢„è§ˆå›¾ç‰‡å¤±è´¥: {e}")
                # é¢„è§ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
        
        # å¦‚æœæœ‰é¢„è§ˆæ¶ˆæ¯ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé¢„è§ˆæ¶ˆæ¯çš„é“¾æ¥å¹¶ä¿å­˜æ‰€æœ‰ message_id
        if preview_messages:
            preview_msg_id = preview_messages[0].message_id
            preview_msg_ids = [msg.message_id for msg in preview_messages]
            resource.preview_message_id = preview_msg_id  # å‘åå…¼å®¹
            resource.preview_message_ids = preview_msg_ids  # å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯ID
            formatted_id = format_channel_id_for_link(settings.channels.comic_preview_channel_id)
            resource.preview_url = f"https://t.me/c/{formatted_id}/{preview_msg_id}"
        else:
            resource.preview_url = deep_link
            
            for order, file_data in enumerate(stored_file_ids, start=1):
                if isinstance(file_data, tuple):
                    file_id, message_id = file_data
                else:
                    file_id = file_data
                    message_id = None
                session.add(
                    ComicFile(
                        resource_id=resource.id,
                        file_id=file_id,
                        order=order,
                        storage_message_id=message_id,
                    )
                )

        session.flush()
        logger.info(f"âœ… æ¼«ç”»åˆ›å»ºæˆåŠŸ: id={resource.id}, title={title}, deep_link={deep_link}")
        # db_session() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šåœ¨é€€å‡ºæ—¶è‡ªåŠ¨æäº¤
        return ComicUploadResponse(
            id=resource.id,
            pages=len(stored_file_ids),
            deep_link=deep_link,
            preview_link=resource.preview_url,
        )


def extract_images_from_archive(archive_path: Path, archive_type: str) -> tuple[List[Path], str]:
    """ä»å‹ç¼©åŒ…ä¸­æå–å›¾ç‰‡æ–‡ä»¶ï¼Œè¿”å›å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨å’Œä¸´æ—¶ç›®å½•è·¯å¾„"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp'}
    images = []
    extracted_dir = tempfile.mkdtemp()
    
    try:
        if archive_type == 'zip':
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                namelist = zip_ref.namelist()
                logger.info(f"ZIP æ–‡ä»¶åŒ…å« {len(namelist)} ä¸ªæ–‡ä»¶")
                image_count = 0
                for member in namelist:
                    member_path = Path(member)
                    if member_path.suffix.lower() in image_extensions:
                        # æå–åˆ°ä¸´æ—¶ç›®å½•
                        zip_ref.extract(member, extracted_dir)
                        full_path = Path(extracted_dir) / member_path
                        if full_path.exists() and full_path.is_file():
                            images.append(full_path)
                            image_count += 1
                logger.info(f"ZIP æ–‡ä»¶è§£å‹å®Œæˆï¼šæˆåŠŸæå– {image_count} å¼ å›¾ç‰‡")
        elif archive_type == 'rar':
            # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿå‘½ä»¤è§£å‹ RAR æ–‡ä»¶ï¼Œæ›´å¯é 
            import subprocess
            import shutil as shutil_module
            
            # å°è¯•ä½¿ç”¨ unar æˆ– unrar å‘½ä»¤ï¼ˆè·¨å¹³å°æ”¯æŒï¼‰
            unar_cmd = None
            # åœ¨ Linux ä¸Šï¼Œä¼˜å…ˆå°è¯• unrarï¼Œç„¶åæ˜¯ unar
            # åœ¨ macOS ä¸Šï¼Œä¼˜å…ˆå°è¯• unarï¼Œç„¶åæ˜¯ unrar
            import platform
            system = platform.system().lower()
            if system == 'linux':
                cmd_order = ['unrar', 'unar']
            else:  # macOS, Windows ç­‰
                cmd_order = ['unar', 'unrar']
            
            for cmd in cmd_order:
                try:
                    result = subprocess.run(
                        [cmd, '--version'] if cmd == 'unar' else [cmd],
                        capture_output=True,
                        timeout=5,
                        text=True
                    )
                    unar_cmd = cmd
                    logger.info(f"æ‰¾åˆ°è§£å‹å·¥å…·: {cmd} (ç³»ç»Ÿ: {system})")
                    break
                except (FileNotFoundError, subprocess.TimeoutExpired):
                    continue
            
            if unar_cmd:
                # ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤è§£å‹
                try:
                    logger.info(f"ä½¿ç”¨ {unar_cmd} è§£å‹ RAR æ–‡ä»¶: {archive_path}")
                    if unar_cmd == 'unar':
                        # unar å‘½ä»¤æ ¼å¼: unar -o output_dir file.rar
                        result = subprocess.run(
                            [unar_cmd, '-o', extracted_dir, str(archive_path)],
                            capture_output=True,
                            timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                            text=True,
                            check=True
                        )
                    else:  # unrar
                        # unrar å‘½ä»¤æ ¼å¼: unrar x file.rar output_dir/
                        result = subprocess.run(
                            [unar_cmd, 'x', '-y', str(archive_path), f'{extracted_dir}/'],
                            capture_output=True,
                            timeout=300,
                            text=True,
                            check=True
                        )
                    
                    logger.info(f"{unar_cmd} è§£å‹æˆåŠŸ")
                    
                    # æ‰«æè§£å‹åçš„æ–‡ä»¶
                    for root, dirs, files in os.walk(extracted_dir):
                        for file in files:
                            file_path = Path(root) / file
                            if file_path.suffix.lower() in image_extensions:
                                if file_path.exists() and file_path.is_file() and file_path.stat().st_size > 0:
                                    images.append(file_path)
                    
                    image_count = len(images)
                    logger.info(f"RAR æ–‡ä»¶è§£å‹å®Œæˆï¼šæˆåŠŸæå– {image_count} å¼ å›¾ç‰‡")
                    
                    if image_count == 0:
                        raise ValueError("RAR æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
                        
                except subprocess.CalledProcessError as e:
                    error_msg = e.stderr if e.stderr else e.stdout if e.stdout else str(e)
                    logger.error(f"{unar_cmd} è§£å‹å¤±è´¥: {error_msg}")
                    raise ValueError(f"ä½¿ç”¨ {unar_cmd} è§£å‹ RAR æ–‡ä»¶å¤±è´¥: {error_msg}")
                except subprocess.TimeoutExpired:
                    raise ValueError(f"è§£å‹ RAR æ–‡ä»¶è¶…æ—¶ï¼ˆè¶…è¿‡ 5 åˆ†é’Ÿï¼‰")
                except Exception as e:
                    logger.error(f"è§£å‹ RAR æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    raise ValueError(f"è§£å‹ RAR æ–‡ä»¶å¤±è´¥: {str(e)}")
            elif RAR_SUPPORT:
                # å›é€€åˆ° rarfile åº“ï¼ˆä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼‰
                logger.warning("æœªæ‰¾åˆ°ç³»ç»Ÿè§£å‹å·¥å…·ï¼Œä½¿ç”¨ rarfile åº“ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰")
                try:
                    with rarfile.RarFile(archive_path, 'r') as rar_ref:
                        try:
                            namelist = rar_ref.namelist()
                        except Exception as e:
                            raise ValueError(f"æ— æ³•è¯»å– RAR æ–‡ä»¶åˆ—è¡¨: {str(e)}ã€‚å»ºè®®å®‰è£… unar å·¥å…·: brew install unar")
                        
                        if not namelist:
                            raise ValueError("RAR æ–‡ä»¶ä¸ºç©ºï¼šæ— æ³•è¯»å–æ–‡ä»¶åˆ—è¡¨")
                        
                        logger.info(f"RAR æ–‡ä»¶åŒ…å« {len(namelist)} ä¸ªæ–‡ä»¶")
                        image_count = 0
                        for member in namelist:
                            member_path = Path(member)
                            if member_path.suffix.lower() in image_extensions:
                                try:
                                    # å°è¯•ä½¿ç”¨ open æ–¹æ³•ç›´æ¥è¯»å–ï¼ˆæ›´å¯é ï¼‰
                                    with rar_ref.open(member) as f:
                                        content = f.read()
                                        if content:
                                            full_path = Path(extracted_dir) / member_path
                                            full_path.parent.mkdir(parents=True, exist_ok=True)
                                            with open(full_path, 'wb') as out:
                                                out.write(content)
                                            if full_path.exists() and full_path.stat().st_size > 0:
                                                images.append(full_path)
                                                image_count += 1
                                except Exception as e:
                                    logger.warning(f"è§£å‹æ–‡ä»¶ {member} å¤±è´¥: {e}")
                                    continue
                        
                        if image_count == 0:
                            raise ValueError("RAR æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶æˆ–æ‰€æœ‰æ–‡ä»¶è§£å‹å¤±è´¥ã€‚å»ºè®®å®‰è£… unar å·¥å…·: brew install unar")
                        logger.info(f"ä½¿ç”¨ rarfile åº“è§£å‹å®Œæˆï¼šæˆåŠŸæå– {image_count} å¼ å›¾ç‰‡")
                except Exception as e:
                    raise ValueError(f"è§£å‹ RAR æ–‡ä»¶å¤±è´¥: {str(e)}ã€‚å»ºè®®å®‰è£… unar å·¥å…·: brew install unar")
            else:
                raise ValueError("æ— æ³•è§£å‹ RAR æ–‡ä»¶ï¼šæœªæ‰¾åˆ°è§£å‹å·¥å…·ã€‚è¯·å®‰è£… unar: brew install unar æˆ– unrar å·¥å…·")
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„å‹ç¼©åŒ…æ ¼å¼: {archive_type}")
    except Exception as e:
        logger.error(f"è§£å‹å¤±è´¥: {e}")
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(extracted_dir)
        except:
            pass
        raise HTTPException(status_code=400, detail=f"è§£å‹å¤±è´¥: {str(e)}")
    
    # è¿‡æ»¤æ‰ macOS éšè—æ–‡ä»¶ï¼ˆä»¥ ._ å¼€å¤´çš„æ–‡ä»¶ï¼‰å’Œå…¶ä»–ç³»ç»Ÿæ–‡ä»¶
    images = [img for img in images if not img.name.startswith('._') and not img.name.startswith('.DS_Store')]
    
    # æŒ‰æ–‡ä»¶åæ’åº
    images.sort(key=lambda p: str(p.name).lower())
    return images, extracted_dir


@app.post("/resources/comics/archive", response_model=ComicUploadResponse)
async def upload_comic_archive(
    title: Annotated[str, Form()],
    archive: Annotated[UploadFile, File(..., description="å‹ç¼©åŒ…æ–‡ä»¶ (zip/rar)")],
    _: Annotated[str, Depends(require_admin)],
    is_vip: Annotated[bool, Form()] = False,
    preview_count: Annotated[int, Form()] = 5,
):
    """ä¸Šä¼ å‹ç¼©åŒ…å¹¶è‡ªåŠ¨è§£å‹ã€å‘é€åˆ°å­˜å‚¨é¢‘é“å’Œé¢„è§ˆé¢‘é“"""
    if not archive.filename:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
    
    # åˆ¤æ–­å‹ç¼©åŒ…ç±»å‹
    filename_lower = archive.filename.lower()
    if filename_lower.endswith('.zip'):
        archive_type = 'zip'
    elif filename_lower.endswith('.rar'):
        if not RAR_SUPPORT:
            raise HTTPException(status_code=400, detail="RAR æ ¼å¼éœ€è¦å®‰è£… rarfile åº“")
        archive_type = 'rar'
    else:
        raise HTTPException(status_code=400, detail="ä»…æ”¯æŒ zip å’Œ rar æ ¼å¼")
    
    # ä¿å­˜å‹ç¼©åŒ…åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆæµå¼å¤„ç†ï¼Œé¿å…å¤§æ–‡ä»¶å†…å­˜æº¢å‡ºï¼‰
    logger.info(f"å¼€å§‹æ¥æ”¶å‹ç¼©åŒ…: {archive.filename}, å¤§å°: {archive.size if hasattr(archive, 'size') else 'æœªçŸ¥'}")
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{archive_type}") as tmp_archive:
        tmp_archive_path = Path(tmp_archive.name)
        # æµå¼è¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
        chunk_size = 1024 * 1024  # 1MB chunks
        total_size = 0
        # ç§»é™¤æ–‡ä»¶å¤§å°é™åˆ¶ï¼Œæ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ ï¼ˆ2GB+ï¼‰
        max_size = 2 * 1024 * 1024 * 1024  # 2GB é™åˆ¶ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
        while True:
            chunk = await archive.read(chunk_size)
            if not chunk:
                break
            total_size += len(chunk)
            if total_size > max_size:
                raise HTTPException(status_code=413, detail=f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({max_size / 1024 / 1024 / 1024:.1f}GB)")
            tmp_archive.write(chunk)
            tmp_archive.flush()  # ç«‹å³åˆ·æ–°ç¼“å†²åŒº
            # æ¯ 100MB è®°å½•ä¸€æ¬¡è¿›åº¦
            if total_size % (100 * 1024 * 1024) < chunk_size:
                logger.info(f"æ¥æ”¶è¿›åº¦: {total_size / 1024 / 1024:.2f}MB")
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å†™å…¥ç£ç›˜
        tmp_archive.flush()
        os.fsync(tmp_archive.fileno())  # å¼ºåˆ¶åŒæ­¥åˆ°ç£ç›˜
        logger.info(f"å‹ç¼©åŒ…æ¥æ”¶å®Œæˆ: {archive.filename}, å®é™…å¤§å°: {total_size / 1024 / 1024:.2f}MB")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å®Œæ•´
        actual_file_size = tmp_archive_path.stat().st_size
        if actual_file_size != total_size:
            raise HTTPException(status_code=400, detail=f"æ–‡ä»¶å†™å…¥ä¸å®Œæ•´: æœŸæœ› {total_size} å­—èŠ‚ï¼Œå®é™… {actual_file_size} å­—èŠ‚")
    
    extracted_dir = None
    try:
        # è§£å‹å¹¶æå–å›¾ç‰‡
        image_files, extracted_dir = extract_images_from_archive(tmp_archive_path, archive_type)
        if not image_files:
            raise HTTPException(status_code=400, detail="å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        
        # å‘é€æ‰€æœ‰å›¾ç‰‡åˆ°å­˜å‚¨é¢‘é“ï¼ˆä½¿ç”¨åª’ä½“ç»„æ‰¹é‡å‘é€ï¼Œæ¯10å¼ ä¸€ç»„ï¼‰
        stored_file_ids: list[tuple[str, int]] = []
        # Telegram é™åˆ¶ï¼šåª’ä½“ç»„æœ€å¤š10ä¸ªæ–‡ä»¶
        chunk_size_media = 10
        for i in range(0, len(image_files), chunk_size_media):
            chunk = image_files[i:i + chunk_size_media]
            media_group = []
            for img_path in chunk:
                with open(img_path, 'rb') as f:
                    img_content = f.read()
                buffer = BufferedInputFile(img_content, filename=img_path.name)
                media_group.append(InputMediaPhoto(media=buffer))
            
            try:
                # ä½¿ç”¨åª’ä½“ç»„æ‰¹é‡å‘é€
                messages = await admin_bot.send_media_group(
                    settings.channels.storage_channel_id,
                    media=media_group,
                )
                # ä»è¿”å›çš„æ¶ˆæ¯ä¸­æå– file_id å’Œ message_id
                for message in messages:
                    if message.photo:
                        stored_file_ids.append((message.photo[-1].file_id, message.message_id))
                logger.info(f"æˆåŠŸå‘é€åª’ä½“ç»„: {len(messages)} å¼ å›¾ç‰‡")
                # æ¯ç»„ä¹‹é—´ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è§¦å‘ Flood control
                if i + chunk_size_media < len(image_files):
                    await asyncio.sleep(0.5)
            except TelegramRetryAfter as e:
                wait_time = e.retry_after + 1
                logger.warning(f"è§¦å‘ Flood controlï¼Œç­‰å¾… {wait_time} ç§’")
                await asyncio.sleep(wait_time)
                # é‡è¯•å‘é€è¿™ä¸€ç»„
                messages = await admin_bot.send_media_group(
                    settings.channels.storage_channel_id,
                    media=media_group,
                )
                for message in messages:
                    if message.photo:
                        stored_file_ids.append((message.photo[-1].file_id, message.message_id))
            except Exception as e:
                logger.error(f"å‘é€åª’ä½“ç»„å¤±è´¥: {e}")
                raise HTTPException(status_code=500, detail=f"å‘é€å›¾ç‰‡å¤±è´¥: {str(e)}")
        
        # æå– file_idï¼ˆå¦‚æœæ˜¯å…ƒç»„åˆ™å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        cover_file_id = stored_file_ids[0][0] if isinstance(stored_file_ids[0], tuple) else stored_file_ids[0]
        bot_username = await get_bot_username()
        
        with db_session() as session:
            resource = Resource(
                title=title,
                type="comic",
                cover_file_id=cover_file_id,
                is_vip=is_vip,
                preview_url=None,  # è‡ªåŠ¨ç”Ÿæˆï¼Œä¸æ‰‹åŠ¨è®¾ç½®
            )
            session.add(resource)
            session.flush()
            
            deep_link = f"https://t.me/{bot_username}?start=comic_{resource.id}"
            
            # å‘é€å‰å‡ å¼ å›¾ç‰‡åˆ°é¢„è§ˆé¢‘é“ï¼ˆä½œä¸ºä¸€æ¡åª’ä½“ç»„æ¶ˆæ¯ï¼‰ï¼Œç¬¬ä¸€å¼ å›¾ç‰‡çš„captionåŒ…å«è¶…é“¾æ¥
            # stored_file_ids é‡Œçš„å…ƒç´ å¯èƒ½æ˜¯ file_id æˆ– (file_id, message_id) å…ƒç»„ï¼Œè¿™é‡Œç»Ÿä¸€åªå– file_id
            preview_file_ids = [
                (item[0] if isinstance(item, tuple) else item)
                for item in stored_file_ids[:min(preview_count, len(stored_file_ids))]
            ]
            preview_messages = []
            if preview_file_ids:
                try:
                    # ç¬¬ä¸€å¼ å›¾ç‰‡æ·»åŠ captionï¼ˆåŒ…å«è¶…é“¾æ¥ï¼‰ï¼Œå…¶ä»–å›¾ç‰‡ä¸æ·»åŠ caption
                    media_group = []
                    for idx, file_id in enumerate(preview_file_ids):
                        if idx == 0:
                            caption = f'ğŸ“– <a href="{deep_link}">{title}</a>'
                            media_group.append(
                                InputMediaPhoto(
                                    media=file_id,
                                    caption=caption,
                                    parse_mode="HTML",
                                )
                            )
                        else:
                            media_group.append(InputMediaPhoto(media=file_id))
                    messages = await admin_bot.send_media_group(
                        settings.channels.comic_preview_channel_id,
                        media=media_group,
                    )
                    preview_messages.extend(messages)
                except Exception as e:
                    logger.error(f"å‘é€é¢„è§ˆå›¾ç‰‡å¤±è´¥: {e}")
                    # é¢„è§ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
            
            # å¦‚æœæœ‰é¢„è§ˆæ¶ˆæ¯ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé¢„è§ˆæ¶ˆæ¯çš„é“¾æ¥å¹¶ä¿å­˜æ‰€æœ‰ message_id
            if preview_messages:
                preview_msg_id = preview_messages[0].message_id
                preview_msg_ids = [msg.message_id for msg in preview_messages]
                resource.preview_message_id = preview_msg_id  # å‘åå…¼å®¹
                resource.preview_message_ids = preview_msg_ids  # å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯ID
                formatted_id = format_channel_id_for_link(settings.channels.comic_preview_channel_id)
                resource.preview_url = f"https://t.me/c/{formatted_id}/{preview_msg_id}"
            else:
                resource.preview_url = deep_link
            
            for order, file_data in enumerate(stored_file_ids, start=1):
                if isinstance(file_data, tuple):
                    file_id, message_id = file_data
                else:
                    file_id = file_data
                    message_id = None
                session.add(
                    ComicFile(
                        resource_id=resource.id,
                        file_id=file_id,
                        order=order,
                        storage_message_id=message_id,
                    )
                )
            
            session.flush()
            logger.info(f"âœ… æ¼«ç”»åˆ›å»ºæˆåŠŸ: id={resource.id}, title={title}, deep_link={deep_link}")
            # db_session() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šåœ¨é€€å‡ºæ—¶è‡ªåŠ¨æäº¤
            return ComicUploadResponse(
                id=resource.id,
                pages=len(stored_file_ids),
                deep_link=deep_link,
                preview_link=resource.preview_url,
            )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if tmp_archive_path.exists():
                tmp_archive_path.unlink()
        except:
            pass
        try:
            if extracted_dir and Path(extracted_dir).exists():
                shutil.rmtree(extracted_dir)
        except:
            pass


@app.post("/resources/comics/batch-archive", response_model=List[ComicUploadResponse])
async def batch_upload_comic_archives(
    archives: Annotated[list[UploadFile], File(..., description="å‹ç¼©åŒ…æ–‡ä»¶åˆ—è¡¨ (zip/rar)")],
    _: Annotated[str, Depends(require_admin)],
    is_vip: Annotated[bool, Form()] = False,
    preview_count: Annotated[int, Form()] = 5,
):
    """æ‰¹é‡ä¸Šä¼ å‹ç¼©åŒ…å¹¶è‡ªåŠ¨è§£å‹ã€å‘é€åˆ°å­˜å‚¨é¢‘é“å’Œé¢„è§ˆé¢‘é“"""
    try:
        logger.info(f"æ”¶åˆ°æ‰¹é‡ä¸Šä¼ è¯·æ±‚: {len(archives) if archives else 0} ä¸ªæ–‡ä»¶")
        if not archives:
            logger.error("æ‰¹é‡ä¸Šä¼ è¯·æ±‚ï¼šæ²¡æœ‰æ–‡ä»¶")
            raise HTTPException(status_code=400, detail="è‡³å°‘ä¸Šä¼ ä¸€ä¸ªå‹ç¼©åŒ…")
        
        # è®°å½•æ–‡ä»¶ä¿¡æ¯
        for idx, archive in enumerate(archives):
            if archive.filename:
                logger.info(f"æ–‡ä»¶ {idx+1}: {archive.filename}, å¤§å°: {archive.size if hasattr(archive, 'size') else 'æœªçŸ¥'}")
        
        # æ£€æŸ¥ RAR æ”¯æŒ
        if not RAR_SUPPORT:
            rar_files = [f.filename for f in archives if f.filename and f.filename.lower().endswith('.rar')]
            if rar_files:
                logger.error(f"æ£€æµ‹åˆ° RAR æ–‡ä»¶ä½†æœªå®‰è£… rarfile åº“: {rar_files}")
                raise HTTPException(
                    status_code=400, 
                    detail=f"RAR æ ¼å¼éœ€è¦å®‰è£… rarfile åº“ã€‚è¯·è¿è¡Œ: pip install rarfile"
                )
        
        results = []
        processed_count = 0
        skipped_count = 0
        for archive in archives:
            processed_count += 1
            logger.info(f"å¤„ç†æ–‡ä»¶ {processed_count}/{len(archives)}: {archive.filename if archive.filename else 'æ— æ–‡ä»¶å'}")
            if not archive.filename:
                logger.warning(f"æ–‡ä»¶ {processed_count}: è·³è¿‡ï¼ˆæ— æ–‡ä»¶åï¼‰")
                skipped_count += 1
                continue
            
            # åˆ¤æ–­å‹ç¼©åŒ…ç±»å‹
            filename_lower = archive.filename.lower()
            if filename_lower.endswith('.zip'):
                archive_type = 'zip'
            elif filename_lower.endswith('.rar'):
                if not RAR_SUPPORT:
                    logger.warning(f"è·³è¿‡ {archive.filename}: RAR æ ¼å¼éœ€è¦å®‰è£… rarfile åº“")
                    skipped_count += 1
                    continue
                archive_type = 'rar'
            else:
                logger.warning(f"è·³è¿‡ {archive.filename}: ä»…æ”¯æŒ zip å’Œ rar æ ¼å¼ï¼ˆå½“å‰æ‰©å±•å: {Path(archive.filename).suffix}ï¼‰")
                skipped_count += 1
                continue
            
            # ä½¿ç”¨æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰ä½œä¸ºæ ‡é¢˜
            title = Path(archive.filename).stem
            
            # ä¿å­˜å‹ç¼©åŒ…åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆæµå¼å¤„ç†ï¼Œé¿å…å¤§æ–‡ä»¶å†…å­˜æº¢å‡ºï¼‰
            logger.info(f"å¼€å§‹æ¥æ”¶å‹ç¼©åŒ…: {archive.filename}, å¤§å°: {archive.size if hasattr(archive, 'size') else 'æœªçŸ¥'}")
            tmp_archive_path = None
            file_too_large = False
            total_size = 0
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{archive_type}") as tmp_archive:
                    tmp_archive_path = Path(tmp_archive.name)
                    # æµå¼è¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
                    chunk_size = 1024 * 1024  # 1MB chunks
                    # ç§»é™¤æ–‡ä»¶å¤§å°é™åˆ¶ï¼Œæ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ ï¼ˆ2GB+ï¼‰
                    max_size = 2 * 1024 * 1024 * 1024  # 2GB é™åˆ¶ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                    chunk_count = 0
                    while True:
                        chunk = await archive.read(chunk_size)
                        if not chunk:
                            break
                        chunk_count += 1
                        total_size += len(chunk)
                        if total_size > max_size:
                            logger.warning(f"è·³è¿‡ {archive.filename}: æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({max_size / 1024 / 1024 / 1024:.1f}GB)")
                            file_too_large = True
                            # è·³å‡ºå¾ªç¯ï¼Œè·³è¿‡è¿™ä¸ªæ–‡ä»¶
                            break
                        tmp_archive.write(chunk)
                        tmp_archive.flush()  # ç«‹å³åˆ·æ–°ç¼“å†²åŒºï¼Œç¡®ä¿æ•°æ®å†™å…¥ç£ç›˜
                        # æ¯ 100MB è®°å½•ä¸€æ¬¡è¿›åº¦
                        if total_size % (100 * 1024 * 1024) < chunk_size:
                            logger.info(f"æ¥æ”¶è¿›åº¦ {archive.filename}: {total_size / 1024 / 1024:.2f}MB")
                    
                    # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å†™å…¥ç£ç›˜
                    tmp_archive.flush()
                    os.fsync(tmp_archive.fileno())  # å¼ºåˆ¶åŒæ­¥åˆ°ç£ç›˜
                    
                    if total_size == 0:
                        logger.error(f"è·³è¿‡ {archive.filename}: æ–‡ä»¶ä¸ºç©ºï¼ˆå¯èƒ½æ–‡ä»¶æ•°æ®æœªæ­£ç¡®ä¼ è¾“ï¼‰")
                        file_too_large = True  # ä½¿ç”¨è¿™ä¸ªæ ‡å¿—æ¥è·³è¿‡ç©ºæ–‡ä»¶
                        skipped_count += 1
                    else:
                        logger.info(f"å‹ç¼©åŒ…æ¥æ”¶å®Œæˆ: {archive.filename}, å®é™…å¤§å°: {total_size / 1024 / 1024:.2f}MB")
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆæ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åŒ¹é…ï¼‰
                        if hasattr(archive, 'size') and archive.size and total_size != archive.size:
                            logger.warning(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {archive.filename}, æœŸæœ›: {archive.size}, å®é™…: {total_size}")
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨ä¸”å¯è¯»
                        if tmp_archive_path.exists():
                            actual_file_size = tmp_archive_path.stat().st_size
                            if actual_file_size != total_size:
                                logger.error(f"æ–‡ä»¶å†™å…¥ä¸å®Œæ•´: {archive.filename}, æœŸæœ›: {total_size}, å®é™…æ–‡ä»¶å¤§å°: {actual_file_size}")
                                file_too_large = True
                                skipped_count += 1
            except Exception as e:
                logger.error(f"æ¥æ”¶å‹ç¼©åŒ… {archive.filename} æ—¶å‡ºé”™: {e}", exc_info=True)
                if tmp_archive_path and tmp_archive_path.exists():
                    try:
                        tmp_archive_path.unlink()
                    except:
                        pass
                continue
            
            # å¦‚æœæ–‡ä»¶è¶…è¿‡å¤§å°é™åˆ¶ï¼Œè·³è¿‡å¤„ç†
            if file_too_large:
                if tmp_archive_path and tmp_archive_path.exists():
                    try:
                        tmp_archive_path.unlink()
                    except:
                        pass
                skipped_count += 1
                continue
            
            if not tmp_archive_path or not tmp_archive_path.exists():
                logger.warning(f"è·³è¿‡ {archive.filename}: ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨")
                skipped_count += 1
                continue
            
            # åœ¨è§£å‹å‰éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
            try:
                actual_size = tmp_archive_path.stat().st_size
                if actual_size == 0:
                    logger.error(f"è·³è¿‡ {archive.filename}: ä¸´æ—¶æ–‡ä»¶å¤§å°ä¸º 0")
                    skipped_count += 1
                    if tmp_archive_path.exists():
                        try:
                            tmp_archive_path.unlink()
                        except:
                            pass
                    continue
                if total_size > 0 and actual_size != total_size:
                    logger.error(f"è·³è¿‡ {archive.filename}: æ–‡ä»¶å†™å…¥ä¸å®Œæ•´ï¼ŒæœŸæœ›: {total_size} å­—èŠ‚ï¼Œå®é™…: {actual_size} å­—èŠ‚")
                    skipped_count += 1
                    if tmp_archive_path.exists():
                        try:
                            tmp_archive_path.unlink()
                        except:
                            pass
                    continue
                logger.info(f"ä¸´æ—¶æ–‡ä»¶éªŒè¯é€šè¿‡: {archive.filename}, å¤§å°: {actual_size / 1024 / 1024:.2f}MB")
            except Exception as e:
                logger.error(f"éªŒè¯ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {archive.filename}: {e}")
                skipped_count += 1
                continue
            
            extracted_dir = None
            try:
                # è§£å‹å¹¶æå–å›¾ç‰‡
                logger.info(f"å¼€å§‹è§£å‹: {archive.filename}, æ–‡ä»¶å¤§å°: {tmp_archive_path.stat().st_size} å­—èŠ‚")
                image_files, extracted_dir = extract_images_from_archive(tmp_archive_path, archive_type)
                if not image_files:
                    logger.warning(f"è·³è¿‡ {archive.filename}: å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼ˆè§£å‹åçš„æ–‡ä»¶åˆ—è¡¨ä¸ºç©ºï¼‰")
                    skipped_count += 1
                    continue
                logger.info(f"è§£å‹æˆåŠŸ: {archive.filename}, æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
                
                # å‘é€æ‰€æœ‰å›¾ç‰‡åˆ°å­˜å‚¨é¢‘é“ï¼ˆä½¿ç”¨åª’ä½“ç»„æ‰¹é‡å‘é€ï¼Œæ¯10å¼ ä¸€ç»„ï¼‰
                stored_file_ids: list[tuple[str, int]] = []
                # Telegram é™åˆ¶ï¼šåª’ä½“ç»„æœ€å¤š10ä¸ªæ–‡ä»¶
                media_chunk_size = 10
                for i in range(0, len(image_files), media_chunk_size):
                    chunk = image_files[i:i + media_chunk_size]
                    media_group = []
                    for img_path in chunk:
                        with open(img_path, 'rb') as f:
                            img_content = f.read()
                        buffer = BufferedInputFile(img_content, filename=img_path.name)
                        media_group.append(InputMediaPhoto(media=buffer))
                    
                    try:
                        # ä½¿ç”¨åª’ä½“ç»„æ‰¹é‡å‘é€
                        messages = await admin_bot.send_media_group(
                            settings.channels.storage_channel_id,
                            media=media_group,
                        )
                        # ä»è¿”å›çš„æ¶ˆæ¯ä¸­æå– file_id å’Œ message_id
                        for message in messages:
                            if message.photo:
                                stored_file_ids.append((message.photo[-1].file_id, message.message_id))
                        logger.info(f"æˆåŠŸå‘é€åª’ä½“ç»„: {len(messages)} å¼ å›¾ç‰‡")
                        # æ¯ç»„ä¹‹é—´ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è§¦å‘ Flood control
                        if i + media_chunk_size < len(image_files):
                            await asyncio.sleep(0.5)
                    except TelegramRetryAfter as e:
                        wait_time = e.retry_after + 1
                        logger.warning(f"è§¦å‘ Flood controlï¼Œç­‰å¾… {wait_time} ç§’")
                        await asyncio.sleep(wait_time)
                        # é‡è¯•å‘é€è¿™ä¸€ç»„
                        messages = await admin_bot.send_media_group(
                            settings.channels.storage_channel_id,
                            media=media_group,
                        )
                        for message in messages:
                            if message.photo:
                                stored_file_ids.append((message.photo[-1].file_id, message.message_id))
                    except Exception as e:
                        logger.error(f"å‘é€åª’ä½“ç»„å¤±è´¥: {e}")
                        raise HTTPException(status_code=500, detail=f"å‘é€å›¾ç‰‡å¤±è´¥: {str(e)}")
                
                # æå– file_idï¼ˆå¦‚æœæ˜¯å…ƒç»„åˆ™å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
                cover_file_id = stored_file_ids[0][0] if isinstance(stored_file_ids[0], tuple) else stored_file_ids[0]
                bot_username = await get_bot_username()
                
                with db_session() as session:
                    resource = Resource(
                        title=title,
                        type="comic",
                        cover_file_id=cover_file_id,
                        is_vip=is_vip,
                        preview_url=None,
                    )
                    session.add(resource)
                    session.flush()
                    
                    deep_link = f"https://t.me/{bot_username}?start=comic_{resource.id}"
                    
                    # å‘é€å‰å‡ å¼ å›¾ç‰‡åˆ°é¢„è§ˆé¢‘é“ï¼ˆä½œä¸ºä¸€æ¡åª’ä½“ç»„æ¶ˆæ¯ï¼‰ï¼Œç¬¬ä¸€å¼ å›¾ç‰‡çš„captionåŒ…å«è¶…é“¾æ¥
                    # æå– file_idï¼ˆå¦‚æœæ˜¯å…ƒç»„åˆ™å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
                    preview_file_ids = [
                        (item[0] if isinstance(item, tuple) else item) 
                        for item in stored_file_ids[:min(preview_count, len(stored_file_ids))]
                    ]
                    preview_messages = []
                    if preview_file_ids:
                        try:
                            # ç¬¬ä¸€å¼ å›¾ç‰‡æ·»åŠ captionï¼ˆåŒ…å«è¶…é“¾æ¥ï¼‰ï¼Œå…¶ä»–å›¾ç‰‡ä¸æ·»åŠ caption
                            media_group = []
                            for idx, file_id in enumerate(preview_file_ids):
                                if idx == 0:
                                    caption = f'ğŸ“– <a href="{deep_link}">{title}</a>'
                                    media_group.append(InputMediaPhoto(media=file_id, caption=caption, parse_mode="HTML"))
                                else:
                                    media_group.append(InputMediaPhoto(media=file_id))
                            messages = await admin_bot.send_media_group(
                                settings.channels.comic_preview_channel_id,
                                media=media_group,
                            )
                            preview_messages.extend(messages)
                        except Exception as e:
                            logger.error(f"å‘é€é¢„è§ˆå›¾ç‰‡å¤±è´¥: {e}")
                    
                    if preview_messages:
                        preview_msg_id = preview_messages[0].message_id
                        preview_msg_ids = [msg.message_id for msg in preview_messages]
                        resource.preview_message_id = preview_msg_id  # å‘åå…¼å®¹
                        resource.preview_message_ids = preview_msg_ids  # å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯ID
                        formatted_id = format_channel_id_for_link(settings.channels.comic_preview_channel_id)
                        resource.preview_url = f"https://t.me/c/{formatted_id}/{preview_msg_id}"
                    else:
                        resource.preview_url = deep_link
                    
                    for order, file_data in enumerate(stored_file_ids, start=1):
                        if isinstance(file_data, tuple):
                            file_id, message_id = file_data
                        else:
                            file_id = file_data
                            message_id = None
                        session.add(
                            ComicFile(
                                resource_id=resource.id,
                                file_id=file_id,
                                order=order,
                                storage_message_id=message_id,
                            )
                        )
                    
                    session.flush()
                    logger.info(f"âœ… æ¼«ç”»åˆ›å»ºæˆåŠŸ: id={resource.id}, title={title}, deep_link={deep_link}")
                    # db_session() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šåœ¨é€€å‡ºæ—¶è‡ªåŠ¨æäº¤
                    results.append(ComicUploadResponse(
                        id=resource.id,
                        pages=len(stored_file_ids),
                        deep_link=deep_link,
                        preview_link=resource.preview_url,
                    ))
            except Exception as e:
                logger.error(f"å¤„ç†å‹ç¼©åŒ… {archive.filename} å¤±è´¥: {e}", exc_info=True)
                # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªï¼Œä¸ä¸­æ–­æ‰¹é‡ä¸Šä¼ 
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if tmp_archive_path and tmp_archive_path.exists():
                        tmp_archive_path.unlink()
                except:
                    pass
                try:
                    if extracted_dir and Path(extracted_dir).exists():
                        shutil.rmtree(extracted_dir)
                except:
                    pass
        
        if not results:
            logger.error(f"æ‰¹é‡ä¸Šä¼ ï¼šæ²¡æœ‰æˆåŠŸä¸Šä¼ ä»»ä½•å‹ç¼©åŒ…ï¼ˆå¤„ç†: {processed_count}, è·³è¿‡: {skipped_count}, æˆåŠŸ: {len(results)}ï¼‰")
            raise HTTPException(
                status_code=400, 
                detail=f"æ²¡æœ‰æˆåŠŸä¸Šä¼ ä»»ä½•å‹ç¼©åŒ…ã€‚å¤„ç†äº† {processed_count} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡äº† {skipped_count} ä¸ªæ–‡ä»¶ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€å¤§å°å’Œå†…å®¹ã€‚"
            )
        
        logger.info(f"æ‰¹é‡ä¸Šä¼ å®Œæˆ: æˆåŠŸ {len(results)} ä¸ªæ–‡ä»¶")
        return results
    except HTTPException:
        # é‡æ–°æŠ›å‡º HTTP å¼‚å¸¸
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡ä¸Šä¼ å¤„ç†å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸Šä¼ å¤„ç†å¤±è´¥: {str(e)}")


@app.get("/resources/comics/{resource_id}/files", response_model=ComicFilesResponse)
async def get_comic_files(
    resource_id: str,
    _: Annotated[str, Depends(require_admin)],
):
    """è·å–æ¼«ç”»çš„å›¾ç‰‡åˆ—è¡¨"""
    with db_session() as session:
        resource = session.get(Resource, resource_id)
        if not resource:
            raise HTTPException(status_code=404, detail="Resource not found")
        if resource.type != "comic":
            raise HTTPException(status_code=400, detail="Resource is not a comic")
        
        files = session.query(ComicFile).filter(
            ComicFile.resource_id == resource_id
        ).order_by(ComicFile.order).all()
        
        return ComicFilesResponse(
            resource_id=resource.id,
            title=resource.title,
            files=[
                ComicFileResponse(
                    id=file.id,
                    file_id=file.file_id,
                    order=file.order,
                )
                for file in files
            ],
        )


@app.get("/resources/comics/files/{file_id}/url")
async def get_comic_file_url(
    file_id: str,
    _: Annotated[str, Depends(require_admin)],
):
    """è·å– Telegram å›¾ç‰‡çš„ URL"""
    try:
        file = await admin_bot.get_file(file_id)
        file_url = f"https://api.telegram.org/file/bot{settings.bot_token}/{file.file_path}"
        return {"url": file_url}
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶ URL å¤±è´¥: {e}")
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")


@app.put("/resources/comics/{resource_id}/files/order", status_code=204, response_class=Response)
async def update_comic_files_order(
    resource_id: str,
    payload: UpdateComicFilesOrderRequest,
    _: Annotated[str, Depends(require_admin)],
):
    """æ›´æ–°æ¼«ç”»å›¾ç‰‡çš„é¡ºåº"""
    with db_session() as session:
        resource = session.get(Resource, resource_id)
        if not resource:
            raise HTTPException(status_code=404, detail="Resource not found")
        if resource.type != "comic":
            raise HTTPException(status_code=400, detail="Resource is not a comic")
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½å±äºè¿™ä¸ªèµ„æº
        file_ids = {item["id"] for item in payload.file_orders}
        files = session.query(ComicFile).filter(
            ComicFile.id.in_(file_ids),
            ComicFile.resource_id == resource_id
        ).all()
        
        if len(files) != len(file_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†æ–‡ä»¶IDä¸å­˜åœ¨æˆ–ä¸å±äºè¯¥èµ„æº")
        
        # åˆ›å»ºIDåˆ°æ–‡ä»¶çš„æ˜ å°„
        file_map = {file.id: file for file in files}
        
        # æ›´æ–°é¡ºåº
        for item in payload.file_orders:
            file_id = item.get("id")
            order = item.get("order")
            if file_id in file_map:
                file_map[file_id].order = order
        
        session.flush()


@app.get("/settings", response_model=SettingsResponse)
async def get_settings(_: Annotated[str, Depends(require_admin)]):
    return SettingsResponse(
        page_size=settings.bot.page_size,
        search_channel_id=settings.channels.search_channel_id,
        comic_preview_channel_id=settings.channels.comic_preview_channel_id,
        storage_channel_id=settings.channels.storage_channel_id,
    )


@app.get("/users", response_model=List[UserResponse])
async def list_users(
    _: Annotated[str, Depends(require_admin)],
    search: Optional[str] = Query(None),
    skip: int = Query(0, ge=0),
    limit: int = Query(50, ge=1, le=100),
):
    with db_session() as session:
        query = session.query(User)
        if search:
            search_term = f"%{search}%"
            query = query.filter(
                (User.first_name.ilike(search_term))
                | (User.username.ilike(search_term))
                | (User.user_id.cast(String).ilike(search_term))
            )
        users = query.order_by(User.created_at.desc()).offset(skip).limit(limit).all()
    return [
        UserResponse(
            user_id=u.user_id,
            first_name=u.first_name,
            username=u.username,
            vip_expiry=u.vip_expiry,
            is_blocked=u.is_blocked,
            usage_quota=u.usage_quota,
            created_at=u.created_at,
            updated_at=u.updated_at,
        )
        for u in users
    ]


@app.get("/users/count")
async def get_users_count(
    _: Annotated[str, Depends(require_admin)],
    search: Optional[str] = Query(None),
):
    with db_session() as session:
        query = session.query(User)
        if search:
            search_term = f"%{search}%"
            query = query.filter(
                (User.first_name.ilike(search_term))
                | (User.username.ilike(search_term))
                | (User.user_id.cast(String).ilike(search_term))
            )
        count = query.count()
    return {"count": count}


@app.get("/users/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: int,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        user = session.get(User, user_id)
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        return UserResponse(
            user_id=user.user_id,
            first_name=user.first_name,
            username=user.username,
            vip_expiry=user.vip_expiry,
            is_blocked=user.is_blocked,
            usage_quota=user.usage_quota,
            created_at=user.created_at,
            updated_at=user.updated_at,
        )


@app.post("/users", response_model=UserResponse)
async def create_user(
    payload: UserCreateIn,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        existing = session.get(User, payload.user_id)
        if existing:
            raise HTTPException(status_code=400, detail="User already exists")
        user = User(
            user_id=payload.user_id,
            first_name=payload.first_name,
            username=payload.username,
            vip_expiry=payload.vip_expiry,
            is_blocked=payload.is_blocked,
        )
        session.add(user)
        session.flush()
        return UserResponse(
            user_id=user.user_id,
            first_name=user.first_name,
            username=user.username,
            vip_expiry=user.vip_expiry,
            is_blocked=user.is_blocked,
            usage_quota=user.usage_quota,
            created_at=user.created_at,
            updated_at=user.updated_at,
        )


@app.put("/users/{user_id}", response_model=UserResponse)
async def update_user(
    user_id: int,
    payload: UserUpdateIn,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        fields_set = getattr(payload, "model_fields_set", getattr(payload, "__fields_set__", set()))
        user = session.get(User, user_id)
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        if payload.first_name is not None:
            user.first_name = payload.first_name
        if payload.username is not None:
            user.username = payload.username
        if payload.vip_expiry is not None or "vip_expiry" in fields_set:
            user.vip_expiry = payload.vip_expiry
        if payload.is_blocked is not None:
            user.is_blocked = payload.is_blocked
        session.flush()
        return UserResponse(
            user_id=user.user_id,
            first_name=user.first_name,
            username=user.username,
            vip_expiry=user.vip_expiry,
            is_blocked=user.is_blocked,
            usage_quota=user.usage_quota,
            created_at=user.created_at,
            updated_at=user.updated_at,
        )


@app.delete("/users/{user_id}", status_code=204, response_class=Response)
async def delete_user(
    user_id: int,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        user = session.get(User, user_id)
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        session.delete(user)
        session.flush()
    return Response(status_code=204)


@app.post("/users/batch-delete", status_code=204, response_class=Response)
async def batch_delete_users(
    user_ids: Annotated[List[int], Body()],
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        users = session.query(User).filter(User.user_id.in_(user_ids)).all()
        for user in users:
            session.delete(user)
        session.flush()
    return Response(status_code=204)


# ==================== VIP å¥—é¤ç®¡ç† ====================

@app.get("/vip-plans", response_model=List[VipPlanResponse])
async def list_vip_plans(_: Annotated[str, Depends(require_admin)]):
    with db_session() as session:
        plans = session.query(VipPlan).order_by(VipPlan.sort_order.asc(), VipPlan.id.asc()).all()
        return [
            VipPlanResponse(
                id=plan.id,
                name=plan.name,
                duration_days=plan.duration_days,
                price=plan.price,
                description=plan.description,
                is_active=plan.is_active,
                sort_order=plan.sort_order,
                created_at=plan.created_at,
                updated_at=plan.updated_at,
            )
            for plan in plans
        ]


@app.post("/vip-plans", response_model=VipPlanResponse)
async def create_vip_plan(
    payload: VipPlanCreateIn,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        plan = VipPlan(
            name=payload.name,
            duration_days=payload.duration_days,
            price=payload.price,
            description=payload.description,
            is_active=payload.is_active,
            sort_order=payload.sort_order,
        )
        session.add(plan)
        session.flush()
        return VipPlanResponse(
            id=plan.id,
            name=plan.name,
            duration_days=plan.duration_days,
            price=plan.price,
            description=plan.description,
            is_active=plan.is_active,
            sort_order=plan.sort_order,
            created_at=plan.created_at,
            updated_at=plan.updated_at,
        )


@app.put("/vip-plans/{plan_id}", response_model=VipPlanResponse)
async def update_vip_plan(
    plan_id: int,
    payload: VipPlanUpdateIn,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        plan = session.get(VipPlan, plan_id)
        if not plan:
            raise HTTPException(status_code=404, detail="VIP plan not found")
        fields_set = getattr(payload, "model_fields_set", getattr(payload, "__fields_set__", set()))
        if payload.name is not None:
            plan.name = payload.name
        if payload.duration_days is not None:
            plan.duration_days = payload.duration_days
        if payload.price is not None:
            plan.price = payload.price
        if payload.description is not None or "description" in fields_set:
            plan.description = payload.description
        if payload.is_active is not None:
            plan.is_active = payload.is_active
        if payload.sort_order is not None:
            plan.sort_order = payload.sort_order
        session.flush()
        return VipPlanResponse(
            id=plan.id,
            name=plan.name,
            duration_days=plan.duration_days,
            price=plan.price,
            description=plan.description,
            is_active=plan.is_active,
            sort_order=plan.sort_order,
            created_at=plan.created_at,
            updated_at=plan.updated_at,
        )


@app.delete("/vip-plans/{plan_id}", status_code=204, response_class=Response)
async def delete_vip_plan(
    plan_id: int,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        plan = session.get(VipPlan, plan_id)
        if not plan:
            raise HTTPException(status_code=404, detail="VIP plan not found")
        session.delete(plan)
        session.flush()
    return Response(status_code=204)


# ==================== æ”¯ä»˜é…ç½®ç®¡ç† ====================

@app.get("/payment-configs", response_model=List[PaymentConfigResponse])
async def list_payment_configs(_: Annotated[str, Depends(require_admin)]):
    with db_session() as session:
        configs = session.query(PaymentConfig).order_by(PaymentConfig.sort_order.asc(), PaymentConfig.id.asc()).all()
        return [
            PaymentConfigResponse(
                id=config.id,
                payment_type=config.payment_type,
                account_name=config.account_name,
                account_number=config.account_number,
                qr_code_url=config.qr_code_url,
                qr_code_file_id=config.qr_code_file_id,
                is_active=config.is_active,
                sort_order=config.sort_order,
                created_at=config.created_at,
                updated_at=config.updated_at,
            )
            for config in configs
        ]


@app.post("/payment-configs", response_model=PaymentConfigResponse)
async def create_payment_config(
    payload: PaymentConfigCreateIn,
    _: Annotated[str, Depends(require_admin)],
):
    if payload.payment_type not in ("wechat", "alipay"):
        raise HTTPException(status_code=400, detail="payment_type must be 'wechat' or 'alipay'")
    with db_session() as session:
        config = PaymentConfig(
            payment_type=payload.payment_type,
            account_name=payload.account_name,
            account_number=payload.account_number,
            qr_code_url=payload.qr_code_url,
            qr_code_file_id=payload.qr_code_file_id,
            is_active=payload.is_active,
            sort_order=payload.sort_order,
        )
        session.add(config)
        session.flush()
        return PaymentConfigResponse(
            id=config.id,
            payment_type=config.payment_type,
            account_name=config.account_name,
            account_number=config.account_number,
            qr_code_url=config.qr_code_url,
            qr_code_file_id=config.qr_code_file_id,
            is_active=config.is_active,
            sort_order=config.sort_order,
            created_at=config.created_at,
            updated_at=config.updated_at,
        )


@app.put("/payment-configs/{config_id}", response_model=PaymentConfigResponse)
async def update_payment_config(
    config_id: int,
    payload: PaymentConfigUpdateIn,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        config = session.get(PaymentConfig, config_id)
        if not config:
            raise HTTPException(status_code=404, detail="Payment config not found")
        fields_set = getattr(payload, "model_fields_set", getattr(payload, "__fields_set__", set()))
        if payload.account_name is not None or "account_name" in fields_set:
            config.account_name = payload.account_name
        if payload.account_number is not None or "account_number" in fields_set:
            config.account_number = payload.account_number
        if payload.qr_code_url is not None or "qr_code_url" in fields_set:
            config.qr_code_url = payload.qr_code_url
        if payload.qr_code_file_id is not None or "qr_code_file_id" in fields_set:
            config.qr_code_file_id = payload.qr_code_file_id
        if payload.is_active is not None:
            config.is_active = payload.is_active
        if payload.sort_order is not None:
            config.sort_order = payload.sort_order
        session.flush()
        return PaymentConfigResponse(
            id=config.id,
            payment_type=config.payment_type,
            account_name=config.account_name,
            account_number=config.account_number,
            qr_code_url=config.qr_code_url,
            qr_code_file_id=config.qr_code_file_id,
            is_active=config.is_active,
            sort_order=config.sort_order,
            created_at=config.created_at,
            updated_at=config.updated_at,
        )


@app.delete("/payment-configs/{config_id}", status_code=204, response_class=Response)
async def delete_payment_config(
    config_id: int,
    _: Annotated[str, Depends(require_admin)],
):
    with db_session() as session:
        config = session.get(PaymentConfig, config_id)
        if not config:
            raise HTTPException(status_code=404, detail="Payment config not found")
        session.delete(config)
        session.flush()
    return Response(status_code=204)


# ==================== å…¬å¼€çš„æ”¯ä»˜ä¿¡æ¯æ¥å£ï¼ˆä¾›æœºå™¨äººä½¿ç”¨ï¼‰====================

@app.get("/vip/payment-info", response_model=VipPaymentInfoResponse)
async def get_vip_payment_info():
    """è·å– VIP æ”¯ä»˜ä¿¡æ¯ï¼ˆå…¬å¼€æ¥å£ï¼Œä¾›æœºå™¨äººä½¿ç”¨ï¼‰"""
    with db_session() as session:
        # è·å–æ‰€æœ‰å¯ç”¨çš„ VIP å¥—é¤
        plans = (
            session.query(VipPlan)
            .filter(VipPlan.is_active == True)
            .order_by(VipPlan.sort_order.asc(), VipPlan.id.asc())
            .all()
        )
        plan_responses = [
            VipPlanResponse(
                id=plan.id,
                name=plan.name,
                duration_days=plan.duration_days,
                price=plan.price,
                description=plan.description,
                is_active=plan.is_active,
                sort_order=plan.sort_order,
                created_at=plan.created_at,
                updated_at=plan.updated_at,
            )
            for plan in plans
        ]
        
        # è·å–å¯ç”¨çš„æ”¯ä»˜é…ç½®
        wechat_config = (
            session.query(PaymentConfig)
            .filter(PaymentConfig.payment_type == "wechat", PaymentConfig.is_active == True)
            .order_by(PaymentConfig.sort_order.asc())
            .first()
        )
        alipay_config = (
            session.query(PaymentConfig)
            .filter(PaymentConfig.payment_type == "alipay", PaymentConfig.is_active == True)
            .order_by(PaymentConfig.sort_order.asc())
            .first()
        )
        
        wechat_response = None
        if wechat_config:
            wechat_response = PaymentConfigResponse(
                id=wechat_config.id,
                payment_type=wechat_config.payment_type,
                account_name=wechat_config.account_name,
                account_number=wechat_config.account_number,
                qr_code_url=wechat_config.qr_code_url,
                qr_code_file_id=wechat_config.qr_code_file_id,
                is_active=wechat_config.is_active,
                sort_order=wechat_config.sort_order,
                created_at=wechat_config.created_at,
                updated_at=wechat_config.updated_at,
            )
        
        alipay_response = None
        if alipay_config:
            alipay_response = PaymentConfigResponse(
                id=alipay_config.id,
                payment_type=alipay_config.payment_type,
                account_name=alipay_config.account_name,
                account_number=alipay_config.account_number,
                qr_code_url=alipay_config.qr_code_url,
                qr_code_file_id=alipay_config.qr_code_file_id,
                is_active=alipay_config.is_active,
                sort_order=alipay_config.sort_order,
                created_at=alipay_config.created_at,
                updated_at=alipay_config.updated_at,
            )
        
        return VipPaymentInfoResponse(
            plans=plan_responses,
            wechat_config=wechat_response,
            alipay_config=alipay_response,
        )

